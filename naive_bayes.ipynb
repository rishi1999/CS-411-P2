{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b93e9ac6-85dd-4706-8931-fcad1d7ccf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from math import log\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9e2a82a3-b693-4929-9d0d-71a95b380046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    n = len(data) - 1\n",
    "    \n",
    "    # read column headers\n",
    "    line = data[0].strip().split(\", \")\n",
    "    attr_names = line[:-1]\n",
    "    class_var = line[-1]\n",
    "    \n",
    "    class_attr_counts = [ [defaultdict(int) for _ in attr_names] for _ in range(2) ]\n",
    "    class_count = 0\n",
    "\n",
    "    # read data and update counts\n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        c = int(line[-1])\n",
    "        class_count += c\n",
    "        for i, attr_val in enumerate(line[:-1]):\n",
    "            class_attr_counts[c][i][attr_val] += 1\n",
    "    \n",
    "    return n, attr_names, class_var, class_attr_counts, class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "00ac01b1-58bb-44c3-8e25-0d2ac7f58d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed(smoothing, amt, val):\n",
    "    if smoothing:\n",
    "        return val + amt\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3444732b-3b0a-4d17-a146-065c76995d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(file_in, file_out, n, class_attr_counts, class_count, smoothing):\n",
    "    with open(file_in) as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        \n",
    "        missing_flag = False\n",
    "        likelihoods = [log(1-class_count/n), log(class_count/n)]  # logs are used to prevent numerical underflow\n",
    "        for c in range(2):\n",
    "            for i, attr_val in enumerate(line):\n",
    "                if attr_val not in class_attr_counts[c][i]:\n",
    "                    missing_flag = True\n",
    "                    missing_id = c\n",
    "                    if not smoothing:\n",
    "                        break\n",
    "                likelihoods[c] += log(smoothed(\n",
    "                    smoothing, \n",
    "                    1, \n",
    "                    class_attr_counts[c][i][attr_val]))\n",
    "                likelihoods[c] -= log(smoothed(\n",
    "                    smoothing, \n",
    "                    len(class_attr_counts[c][i]), \n",
    "                    sum(class_attr_counts[c][i].values())))\n",
    "        \n",
    "        if missing_flag and not smoothing:\n",
    "            res.append(str(1-missing_id))\n",
    "        elif likelihoods[0] > likelihoods[1]:\n",
    "            res.append(\"0\")\n",
    "        else:\n",
    "            res.append(\"1\")\n",
    "    \n",
    "    with open(file_out, 'w') as f:\n",
    "        f.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ee8049b2-9c43-43f7-b8ed-f69adbca7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_str(n, attr_names, class_var, class_attr_counts, class_count):\n",
    "    res = []\n",
    "    \n",
    "    res.append(f\"P({class_var}=1) = {class_count/n}\")\n",
    "    res.append(f\"P({class_var}=0) = {1-class_count/n}\")\n",
    "    \n",
    "    for c in range(2):\n",
    "        for attr_name, attr in zip(attr_names, class_attr_counts[c]):\n",
    "            total = sum(attr.values())\n",
    "            for key, val in attr.items():\n",
    "                res.append(f\"P({attr_name}={key} | {class_var}={c}) = {val / total}\")\n",
    "    \n",
    "    return '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea80f673-30b1-4c8b-884f-79861baa9b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_train = \"naive_bayes_train.txt\"\n",
    "n, attr_names, class_var, class_attr_counts, class_count = read_train(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "313b7da1-67a4-47bd-96dd-0a70d0f00a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.00018279999494552612\n",
      "\n",
      "P(C=1) = 0.5625\n",
      "P(C=0) = 0.4375\n",
      "P(A1=b | C=0) = 0.42857142857142855\n",
      "P(A1=d | C=0) = 0.14285714285714285\n",
      "P(A1=a | C=0) = 0.14285714285714285\n",
      "P(A1=c | C=0) = 0.2857142857142857\n",
      "P(A2=n | C=0) = 0.2857142857142857\n",
      "P(A2=m | C=0) = 0.2857142857142857\n",
      "P(A2=o | C=0) = 0.42857142857142855\n",
      "P(A3=y | C=0) = 0.2857142857142857\n",
      "P(A3=z | C=0) = 0.2857142857142857\n",
      "P(A3=x | C=0) = 0.2857142857142857\n",
      "P(A3=w | C=0) = 0.14285714285714285\n",
      "P(A1=a | C=1) = 0.4444444444444444\n",
      "P(A1=c | C=1) = 0.3333333333333333\n",
      "P(A1=b | C=1) = 0.2222222222222222\n",
      "P(A2=m | C=1) = 0.3333333333333333\n",
      "P(A2=n | C=1) = 0.5555555555555556\n",
      "P(A2=o | C=1) = 0.1111111111111111\n",
      "P(A3=z | C=1) = 0.2222222222222222\n",
      "P(A3=w | C=1) = 0.2222222222222222\n",
      "P(A3=x | C=1) = 0.3333333333333333\n",
      "P(A3=y | C=1) = 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "train_res = model_str(n, attr_names, class_var, class_attr_counts, class_count)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4528e4f4-26c3-4e05-9dbc-3d7c1dfba384",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7479c354-ba6a-4bd4-ba8b-460a1b43951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.0046885000192560256\n",
      "\n",
      "written to file naive_bayes_output.txt\n"
     ]
    }
   ],
   "source": [
    "file_test = \"naive_bayes_test.txt\"\n",
    "file_out = \"naive_bayes_output.txt\"\n",
    "\n",
    "start = perf_counter()\n",
    "classify(file_test, file_out, n, class_attr_counts, class_count, smoothing)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(f\"written to file {file_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8acf8-b589-43ff-ab56-f7a73d91c261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs411]",
   "language": "python",
   "name": "conda-env-cs411-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
