{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93e9ac6-85dd-4706-8931-fcad1d7ccf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from math import log\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2a82a3-b693-4929-9d0d-71a95b380046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    n = len(data) - 1\n",
    "    \n",
    "    # read column headers\n",
    "    line = data[0].strip().split(\", \")\n",
    "    attr_names = line[:-1]\n",
    "    class_var = line[-1]\n",
    "    \n",
    "    class_attr_counts = [ [defaultdict(int) for _ in attr_names] for _ in range(2) ]\n",
    "    class_count = 0\n",
    "    \n",
    "    attr_domains = [set() for _ in attr_names]\n",
    "\n",
    "    # read data and update counts\n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        c = int(line[-1])\n",
    "        class_count += c\n",
    "        for i, attr_val in enumerate(line[:-1]):\n",
    "            class_attr_counts[c][i][attr_val] += 1\n",
    "            attr_domains[i].add(attr_val)\n",
    "    \n",
    "    return n, attr_names, class_var, class_attr_counts, class_count, attr_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00ac01b1-58bb-44c3-8e25-0d2ac7f58d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed(smoothing, amt, val):\n",
    "    if smoothing:\n",
    "        return val + amt\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8049b2-9c43-43f7-b8ed-f69adbca7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_str(n, attr_names, class_var, class_attr_counts, class_count, attr_domains, smoothing):\n",
    "    res = []\n",
    "    \n",
    "    res.append(f\"P({class_var}=1) = {class_count/n}\")\n",
    "    res.append(f\"P({class_var}=0) = {1-class_count/n}\")\n",
    "    \n",
    "    for c in range(2):\n",
    "        for i, attr in enumerate(class_attr_counts[c]):\n",
    "            total_s = smoothed(smoothing, len(attr_domains[i]), sum(attr.values()))\n",
    "            for key in attr_domains[i]:\n",
    "                val_s = smoothed(smoothing, 1, attr[key])\n",
    "                res.append(f\"P({attr_names[i]}={key} | {class_var}={c}) = {val_s / total_s}\")\n",
    "    \n",
    "    return '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3444732b-3b0a-4d17-a146-065c76995d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(file_in, file_out, n, class_attr_counts, class_count, attr_domains, smoothing):\n",
    "    with open(file_in) as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        \n",
    "        missing_flag = False\n",
    "        likelihoods = [log(1-class_count/n), log(class_count/n)]  # logs are used to prevent numerical underflow\n",
    "        for c in range(2):\n",
    "            for i, attr_val in enumerate(line):\n",
    "                if attr_val not in class_attr_counts[c][i]:\n",
    "                    missing_flag = True\n",
    "                    missing_id = c\n",
    "                    if not smoothing:\n",
    "                        break\n",
    "                likelihoods[c] += log(smoothed(\n",
    "                    smoothing, \n",
    "                    1, \n",
    "                    class_attr_counts[c][i][attr_val]))\n",
    "                likelihoods[c] -= log(smoothed(\n",
    "                    smoothing, \n",
    "                    len(attr_domains[i]), \n",
    "                    sum(class_attr_counts[c][i].values())))\n",
    "        \n",
    "        if missing_flag and not smoothing:\n",
    "            res.append(str(1-missing_id))\n",
    "        elif likelihoods[0] > likelihoods[1]:\n",
    "            res.append(\"0\")\n",
    "        else:\n",
    "            res.append(\"1\")\n",
    "    \n",
    "    with open(file_out, 'w') as f:\n",
    "        f.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4528e4f4-26c3-4e05-9dbc-3d7c1dfba384",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313b7da1-67a4-47bd-96dd-0a70d0f00a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.001824500000111584\n",
      "\n",
      "P(C=1) = 0.5625\n",
      "P(C=0) = 0.4375\n",
      "P(A1=b | C=0) = 0.36363636363636365\n",
      "P(A1=a | C=0) = 0.18181818181818182\n",
      "P(A1=d | C=0) = 0.18181818181818182\n",
      "P(A1=c | C=0) = 0.2727272727272727\n",
      "P(A2=o | C=0) = 0.4\n",
      "P(A2=n | C=0) = 0.3\n",
      "P(A2=m | C=0) = 0.3\n",
      "P(A3=w | C=0) = 0.18181818181818182\n",
      "P(A3=z | C=0) = 0.2727272727272727\n",
      "P(A3=y | C=0) = 0.2727272727272727\n",
      "P(A3=x | C=0) = 0.2727272727272727\n",
      "P(A1=b | C=1) = 0.23076923076923078\n",
      "P(A1=a | C=1) = 0.38461538461538464\n",
      "P(A1=d | C=1) = 0.07692307692307693\n",
      "P(A1=c | C=1) = 0.3076923076923077\n",
      "P(A2=o | C=1) = 0.16666666666666666\n",
      "P(A2=n | C=1) = 0.5\n",
      "P(A2=m | C=1) = 0.3333333333333333\n",
      "P(A3=w | C=1) = 0.23076923076923078\n",
      "P(A3=z | C=1) = 0.23076923076923078\n",
      "P(A3=y | C=1) = 0.23076923076923078\n",
      "P(A3=x | C=1) = 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "file_train = \"naive_bayes_train.txt\"\n",
    "n, attr_names, class_var, class_attr_counts, class_count, attr_domains = read_train(file_train)\n",
    "train_res = model_str(n, attr_names, class_var, class_attr_counts, class_count, attr_domains, smoothing)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7479c354-ba6a-4bd4-ba8b-460a1b43951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.004052300000239484\n",
      "\n",
      "written to file naive_bayes_output.txt\n"
     ]
    }
   ],
   "source": [
    "file_test = \"naive_bayes_test.txt\"\n",
    "file_out = \"naive_bayes_output.txt\"\n",
    "\n",
    "start = perf_counter()\n",
    "classify(file_test, file_out, n, class_attr_counts, class_count, attr_domains, smoothing)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(f\"written to file {file_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8acf8-b589-43ff-ab56-f7a73d91c261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs411]",
   "language": "python",
   "name": "conda-env-cs411-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
