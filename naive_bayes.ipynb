{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93e9ac6-85dd-4706-8931-fcad1d7ccf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from math import log\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2929897-90a2-49bb-abe8-ab205594637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(x):\n",
    "    return log(x) if x != 0 else float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2a82a3-b693-4929-9d0d-71a95b380046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    n = len(data) - 1\n",
    "    \n",
    "    # read column headers\n",
    "    line = data[0].strip().split(\", \")\n",
    "    attr_vars = line[:-1]\n",
    "    class_var = line[-1]\n",
    "    \n",
    "    class_attr_counts = defaultdict( lambda: [defaultdict(int) for _ in attr_vars] )\n",
    "    class_counts = defaultdict(int)\n",
    "    \n",
    "    attr_domains = [set() for _ in attr_vars]\n",
    "    class_domain = set()\n",
    "\n",
    "    # read data and update counts\n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        c = line[-1]\n",
    "        class_counts[c] += 1\n",
    "        class_domain.add(c)\n",
    "        for i, attr_val in enumerate(line[:-1]):\n",
    "            class_attr_counts[c][i][attr_val] += 1\n",
    "            attr_domains[i].add(attr_val)\n",
    "    \n",
    "    return n, attr_vars, class_var, class_attr_counts, class_counts, attr_domains, class_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ac01b1-58bb-44c3-8e25-0d2ac7f58d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed(smoothing, amt, val):\n",
    "    if smoothing:\n",
    "        return val + amt\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee8049b2-9c43-43f7-b8ed-f69adbca7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_str(n, attr_vars, class_var, class_attr_counts, class_counts, attr_domains, class_domain, smoothing):\n",
    "    res = []\n",
    "    \n",
    "    for c in class_domain:\n",
    "        res.append(f\"P({class_var}={c}) = {class_counts[c]/n}\")\n",
    "        for i, attr in enumerate(class_attr_counts[c]):\n",
    "            total_s = smoothed(smoothing, len(attr_domains[i]), sum(attr.values()))\n",
    "            for key in attr_domains[i]:\n",
    "                val_s = smoothed(smoothing, 1, attr[key])\n",
    "                res.append(f\"P({attr_vars[i]}={key} | {class_var}={c}) = {val_s / total_s}\")\n",
    "    \n",
    "    return '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3444732b-3b0a-4d17-a146-065c76995d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(file_in, file_out, n, class_attr_counts, class_counts, attr_domains, class_domain, smoothing):\n",
    "    with open(file_in) as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for line in data[1:]:\n",
    "        line = line.strip().split(\", \")\n",
    "        \n",
    "        likelihoods = {c: safe_log(class_counts[c]/n) for c in class_domain}  # logs are used to prevent numerical underflow\n",
    "        for c in class_domain:\n",
    "            for i, attr_val in enumerate(line):\n",
    "                likelihoods[c] += safe_log(smoothed(\n",
    "                    smoothing, \n",
    "                    1, \n",
    "                    class_attr_counts[c][i][attr_val]))\n",
    "                likelihoods[c] -= safe_log(smoothed(\n",
    "                    smoothing, \n",
    "                    len(attr_domains[i]), \n",
    "                    sum(class_attr_counts[c][i].values())))\n",
    "        \n",
    "        res.append(max(likelihoods, key=lambda x: likelihoods[x]))\n",
    "    \n",
    "    with open(file_out, 'w') as f:\n",
    "        f.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4528e4f4-26c3-4e05-9dbc-3d7c1dfba384",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "313b7da1-67a4-47bd-96dd-0a70d0f00a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.0032063000001016917\n",
      "\n",
      "P(C=Y) = 0.6206896551724138\n",
      "P(A1=o | C=Y) = 0.38095238095238093\n",
      "P(A1=y | C=Y) = 0.2857142857142857\n",
      "P(A1=m | C=Y) = 0.3333333333333333\n",
      "P(A2=t | C=Y) = 0.55\n",
      "P(A2=f | C=Y) = 0.45\n",
      "P(A3=t | C=Y) = 0.7\n",
      "P(A3=f | C=Y) = 0.3\n",
      "P(A4=e | C=Y) = 0.5238095238095238\n",
      "P(A4=g | C=Y) = 0.3333333333333333\n",
      "P(A4=f | C=Y) = 0.14285714285714285\n",
      "P(C=N) = 0.3793103448275862\n",
      "P(A1=o | C=N) = 0.2857142857142857\n",
      "P(A1=y | C=N) = 0.35714285714285715\n",
      "P(A1=m | C=N) = 0.35714285714285715\n",
      "P(A2=t | C=N) = 0.15384615384615385\n",
      "P(A2=f | C=N) = 0.8461538461538461\n",
      "P(A3=t | C=N) = 0.07692307692307693\n",
      "P(A3=f | C=N) = 0.9230769230769231\n",
      "P(A4=e | C=N) = 0.21428571428571427\n",
      "P(A4=g | C=N) = 0.21428571428571427\n",
      "P(A4=f | C=N) = 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "file_train = \"NB-train.txt\"\n",
    "n, attr_vars, class_var, class_attr_counts, class_counts, attr_domains, class_domain = read_train(file_train)\n",
    "train_res = model_str(n, attr_vars, class_var, class_attr_counts, class_counts, attr_domains, class_domain, smoothing)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7479c354-ba6a-4bd4-ba8b-460a1b43951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (s): 0.0249840999999833\n",
      "\n",
      "written to file NB_test_smoothing.txt\n"
     ]
    }
   ],
   "source": [
    "file_test = \"NB-test.txt\"\n",
    "file_out = \"NB_test_smoothing.txt\"\n",
    "\n",
    "start = perf_counter()\n",
    "classify(file_test, file_out, n, class_attr_counts, class_counts, attr_domains, class_domain, smoothing)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"time elapsed (s): {end - start}\\n\")\n",
    "print(f\"written to file {file_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8acf8-b589-43ff-ab56-f7a73d91c261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs411]",
   "language": "python",
   "name": "conda-env-cs411-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
